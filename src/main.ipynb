{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/saaket/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import string \n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('english')\n",
    "import csv\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "import json \n",
    "import numpy as np \n",
    "from src.data_processing import collect_document_ids, split_into_documents, clean_entry, remove_stopwords, read_stopwords_file\n",
    "from src.inverted_index import create_inverted_index, calculate_idf, save_inverted_index\n",
    "from src.config import TOTAL_NUMBER_OF_DOCUMENTS, STARTING_DOCUMENT_INDEX\n",
    "from src.document_ranking import compute_tf_idf_scores\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTING_DOCUMENT_INDEX = 54711"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_string = '''.I 54711\n",
    ".U\n",
    "88000001\n",
    ".S\n",
    "Alcohol Alcohol 8801; 22(2):103-12\n",
    ".M\n",
    "Acetaldehyde/*ME; Buffers; Catalysis; HEPES/PD; Nuclear Magnetic Resonance; Phosphates/*PD; Protein Binding; Ribonuclease, Pancreatic/AI/*ME; Support, U.S. Gov't, Non-P.H.S.; Support, U.S. Gov't, P.H.S..\n",
    ".T\n",
    "The binding of acetaldehyde to the active site of ribonuclease: alterations in catalytic activity and effects of phosphate.\n",
    ".P\n",
    "JOURNAL ARTICLE.\n",
    ".W\n",
    "Ribonuclease A was reacted with [1-13C,1,2-14C]acetaldehyde and sodium cyanoborohydride in the presence or absence of 0.2 M phosphate. After several hours of incubation at 4 degrees C (pH 7.4) stable acetaldehyde-RNase adducts were formed, and the extent of their formation was similar regardless of the presence of phosphate. Although the total amount of covalent binding was comparable in the absence or presence of phosphate, this active site ligand prevented the inhibition of enzymatic activity seen in its absence. This protective action of phosphate diminished with progressive ethylation of RNase, indicating that the reversible association of phosphate with the active site lysyl residue was overcome by the irreversible process of reductive ethylation. Modified RNase was analysed using 13C proton decoupled NMR spectroscopy. Peaks arising from the covalent binding of enriched acetaldehyde to free amino groups in the absence of phosphate were as follows: NH2-terminal alpha amino group, 47.3 ppm; bulk ethylation at epsilon amino groups of nonessential lysyl residues, 43.0 ppm; and the epsilon amino group of lysine-41 at the active site, 47.4 ppm. In the spectrum of RNase ethylated in the presence of phosphate, the peak at 47.4 ppm was absent. When RNase was selectively premethylated in the presence of phosphate, to block all but the active site lysyl residues and then ethylated in its absence, the signal at 43.0 ppm was greatly diminished, and that arising from the active site lysyl residue at 47.4 ppm was enhanced. These results indicate that phosphate specifically protected the active site lysine from reaction with acetaldehyde, and that modification of this lysine by acetaldehyde adduct formation resulted in inhibition of catalytic activity.\n",
    ".A\n",
    "Mauch TJ; Tuma DJ; Sorrell MF.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = split_into_documents('../data/ohsumed.88-91')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_document_ids(corpus):\n",
    "    '''collect a single list of document_ids given the database file'''\n",
    "    document_ids = []\n",
    "    for document in corpus: \n",
    "\n",
    "        pattern = \"\\.U\\n(.*?)\\n\"\n",
    "        doc_id_find = re.search(pattern, document)\n",
    "        if doc_id_find:\n",
    "            doc_id = doc_id_find.group(1)\n",
    "            document_ids.append(doc_id)\n",
    "    return document_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids = collect_document_ids(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inverted_index(corpus, doc_ids):\n",
    "    '''Created inverted index for all unique terms with (document_ids, term_frequncies) in posting list'''\n",
    "    # Create empty inverted index \n",
    "    inverted_index = {}\n",
    "    document_lengths = np.zeros(len(corpus))\n",
    "\n",
    "    # Read stopwords from a stopword file \n",
    "    stopwords_list = read_stopwords_file('stopwords.txt')\n",
    "\n",
    "    # Iterate over the entire courpus of list of documents \n",
    "    for i, document in enumerate(corpus):\n",
    "        doc_id = i\n",
    "\n",
    "        # Clean document \n",
    "        document = clean_entry(document)\n",
    "\n",
    "        # Tokenize document \n",
    "        tokens = document.split(\" \")\n",
    "\n",
    "        # Lowercase all tokens \n",
    "        tokens = [token.lower() for token in tokens]\n",
    "\n",
    "        # Remove stopwords from document \n",
    "        tokens = remove_stopwords(tokens, stopwords_list)\n",
    "\n",
    "        # Calculate and store document lengths \n",
    "        document_lengths[doc_id] = len(tokens)\n",
    "\n",
    "        # Create a dictionary which stores term frequencies \n",
    "        term_frequencies = Counter(tokens)\n",
    "\n",
    "        # Euclidian normalize the term frequencies \n",
    "        denom = np.sum(np.array([(count)**2 for count in term_frequencies.values()]))\n",
    "        denom = np.sqrt(denom)            \n",
    "\n",
    "        # Iterate over all unique terms \n",
    "        for term in term_frequencies.keys():\n",
    "            term_frequencies[term] /= denom\n",
    "            # If the term already exists in inverted index, append the current (doc_id, term_frequency) to the postings list\n",
    "            if term in inverted_index:\n",
    "                inverted_index[term].append((doc_id, term_frequencies[term]))\n",
    "            # If the term does not exist in inverted index, create a entry with the term as key nd add (doc_id, term_frequency) to the posting list\n",
    "            else:\n",
    "                inverted_index[term] = [(doc_id, term_frequencies[term])]\n",
    "    return inverted_index, document_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index, Lengths = create_inverted_index(corpus, doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = calculate_idf(inverted_index, TOTAL_NUMBER_OF_DOCUMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf_idf_scores(inverted_index, query, idf, doc_ids, Lengths):\n",
    "    scores = np.zeros(len(doc_ids))\n",
    "    query = query.split(' ')\n",
    "    tf_query = Counter(query)\n",
    "    for t in query:\n",
    "        if t in inverted_index:\n",
    "            w_tq = tf_query[t] * idf[t]\n",
    "            postings_list = inverted_index[t]\n",
    "            for (d, tf_td) in postings_list:\n",
    "                scores[d] += tf_td * w_tq \n",
    "    for i in range(len(doc_ids)):\n",
    "        scores[i] /= Lengths[i]\n",
    "    \n",
    "    return scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_documents(doc_ids, scores, k):\n",
    "    idx = (-scores).argsort()[:k]\n",
    "    top_k_docs = [(doc_ids[i], scores[i]) for i in idx]\n",
    "    return top_k_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_docs = get_top_k_documents(doc_ids, scores, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    patterns = ['<num>.*\\n', '<desc>.*\\n', '<.*>']\n",
    "    query_id_find = re.search('<num>\\sNumber:\\s(.+?)\\n', query)\n",
    "    if query_id_find:\n",
    "        query_id = query_id_find.group(1)\n",
    "    for pattern in patterns: \n",
    "        query = re.sub(pattern, ' ', query)\n",
    "    query = clean_entry(query)\n",
    "    query = query.split(' ')\n",
    "    query = [q.lower() for q in query]\n",
    "    stop_words_list = read_stopwords_file('stopwords.txt')\n",
    "    query = remove_stopwords(query, stop_words_list)\n",
    "    query = ' '.join(query)\n",
    "    return query, query_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/query.ohsu.1-63') as f:\n",
    "    queries = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = re.split('</top>\\n', queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(method, query, inverted_index, idf, doc_ids, Lengths):\n",
    "    if method == 'tf-idf':\n",
    "        query, query_id = process_query(query)\n",
    "        scores = compute_tf_idf_scores(inverted_index, query, idf, doc_ids, Lengths)\n",
    "        top_k_docs = get_top_k_documents(doc_ids, scores, 1000)\n",
    "        log_string = ''\n",
    "        for rank, (doc_id, score)  in enumerate(top_k_docs):\n",
    "            log_string += f'{query_id} 0 {doc_id} {rank+1} {score} tf-idf\\n'\n",
    "    return log_string \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<top>\\n<num> Number: OHSU1\\n<title> 60 year old menopausal woman without hormone replacement therapy\\n<desc> Description:\\nAre there adverse effects on lipids when progesterone is given with estrogen replacement therapy\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = queries[0]; query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_string = retrieve_documents('tf-idf', query, inverted_index, idf, doc_ids, Lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = queries[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_string = ''\n",
    "for query in queries:\n",
    "    log_string += retrieve_documents('tf-idf', query, inverted_index, idf, doc_ids, Lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('log_file.txt', 'w') as f:\n",
    "    f.write(log_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd46acfb4a95448d935c417fab42f176f820b969729b5c737279b5be8c31c56c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('graphled')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
